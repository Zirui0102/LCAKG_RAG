{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "536bdc9f-b28d-4d54-8fef-a6dd4ee8eaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078d5607-6490-4f80-8da8-f06c33fcc8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"Result_calculation_query.xlsx\"   # replace with actual path\n",
    "data = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "440af9b3-734e-477b-a93a-4b4e0b8a3054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    s = str(text)\n",
    "    s = s.lower().strip()\n",
    "    # replace all dash-like characters with space\n",
    "    s = re.sub(r\"[-–—-]\", \" \", s)    # covers -, –, —, and non-breaking hyphen\n",
    "    s = re.sub(r\"\\s+\", \" \", s)       # collapse multiple spaces\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0294a148-5e98-43cf-bff7-8459cd9a0746",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_1 = data[\"GraphCypherQAChain\"].fillna(\"\").map(normalize_text).tolist()\n",
    "preds_2 = data[\"GraphCypherQAChain with similarity search\"].fillna(\"\").map(normalize_text).tolist()\n",
    "refs  = data[\"Reference result\"].fillna(\"\").map(normalize_text).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee1a37ab-b139-4fc5-ba99-16e25e7b788f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Software\\Anaconda\\envs\\LangChain\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Row-level BERTScores ===\n",
      "Row 1: Precision = 0.839, Recall = 0.887, F1 = 0.862\n",
      "Row 2: Precision = 0.462, Recall = 0.322, F1 = 0.380\n",
      "Row 3: Precision = 0.462, Recall = 0.364, F1 = 0.407\n",
      "Row 4: Precision = 0.418, Recall = 0.409, F1 = 0.413\n",
      "Row 5: Precision = 0.773, Recall = 0.594, F1 = 0.672\n",
      "Row 6: Precision = 0.562, Recall = 0.357, F1 = 0.437\n",
      "Row 7: Precision = 0.469, Recall = 0.402, F1 = 0.433\n",
      "Row 8: Precision = 0.473, Recall = 0.254, F1 = 0.330\n",
      "Row 9: Precision = 0.427, Recall = 0.427, F1 = 0.427\n",
      "Row 10: Precision = 0.612, Recall = 0.653, F1 = 0.632\n",
      "Row 11: Precision = 0.469, Recall = 0.317, F1 = 0.378\n",
      "Row 12: Precision = 0.513, Recall = 0.704, F1 = 0.594\n",
      "Row 13: Precision = 0.467, Recall = 0.405, F1 = 0.433\n",
      "Row 14: Precision = 0.900, Recall = 0.924, F1 = 0.912\n",
      "Row 15: Precision = 0.663, Recall = 0.825, F1 = 0.735\n",
      "Row 16: Precision = 0.681, Recall = 0.887, F1 = 0.771\n",
      "Row 17: Precision = 0.424, Recall = 0.229, F1 = 0.298\n",
      "Row 18: Precision = 0.497, Recall = 0.309, F1 = 0.381\n",
      "Row 19: Precision = 1.000, Recall = 1.000, F1 = 1.000\n",
      "Row 20: Precision = 1.000, Recall = 1.000, F1 = 1.000\n",
      "Row 21: Precision = 0.465, Recall = 0.498, F1 = 0.481\n",
      "Row 22: Precision = 0.864, Recall = 0.711, F1 = 0.780\n",
      "Row 23: Precision = 0.464, Recall = 0.458, F1 = 0.461\n",
      "Row 24: Precision = 0.673, Recall = 0.750, F1 = 0.709\n",
      "Row 25: Precision = 0.802, Recall = 0.855, F1 = 0.828\n",
      "Row 26: Precision = 0.460, Recall = 0.304, F1 = 0.366\n",
      "Row 27: Precision = 0.485, Recall = 0.411, F1 = 0.445\n",
      "Row 28: Precision = 0.890, Recall = 0.944, F1 = 0.916\n",
      "Row 29: Precision = 0.465, Recall = 0.421, F1 = 0.442\n",
      "Row 30: Precision = 0.425, Recall = 0.417, F1 = 0.421\n",
      "Row 31: Precision = 0.759, Recall = 0.830, F1 = 0.793\n",
      "Row 32: Precision = 0.487, Recall = 0.369, F1 = 0.420\n",
      "Row 33: Precision = 0.439, Recall = 0.444, F1 = 0.441\n",
      "Row 34: Precision = 0.436, Recall = 0.471, F1 = 0.453\n",
      "Row 35: Precision = 1.000, Recall = 1.000, F1 = 1.000\n",
      "Row 36: Precision = 0.469, Recall = 0.234, F1 = 0.312\n",
      "Row 37: Precision = 0.448, Recall = 0.541, F1 = 0.490\n",
      "Row 38: Precision = 0.435, Recall = 0.318, F1 = 0.367\n",
      "Row 39: Precision = 0.446, Recall = 0.387, F1 = 0.414\n",
      "Row 40: Precision = 0.442, Recall = 0.410, F1 = 0.426\n",
      "Row 41: Precision = 0.467, Recall = 0.379, F1 = 0.418\n",
      "Row 42: Precision = 0.895, Recall = 0.920, F1 = 0.907\n",
      "Row 43: Precision = 0.849, Recall = 0.857, F1 = 0.853\n",
      "Row 44: Precision = 0.470, Recall = 0.462, F1 = 0.466\n",
      "Row 45: Precision = 0.839, Recall = 0.787, F1 = 0.812\n",
      "Row 46: Precision = 0.449, Recall = 0.383, F1 = 0.413\n",
      "Row 47: Precision = 0.748, Recall = 0.751, F1 = 0.750\n",
      "Row 48: Precision = 0.466, Recall = 0.342, F1 = 0.395\n",
      "Row 49: Precision = 0.550, Recall = 0.639, F1 = 0.591\n",
      "Row 50: Precision = 0.483, Recall = 0.376, F1 = 0.423\n",
      "\n",
      "=== Average BERTScores ===\n",
      "Average Precision: 0.5936\n",
      "Average Recall:    0.5588\n",
      "Average F1:        0.5698\n"
     ]
    }
   ],
   "source": [
    "# Compute BERTScore across rows\n",
    "P, R, F1 = score(preds_1, refs, lang=\"en-sci\", idf=True, rescale_with_baseline=False)\n",
    "\n",
    "# Print per-row precision, recall, and F1\n",
    "print(\"=== Row-level BERTScores ===\")\n",
    "for i, (p, r, f) in enumerate(zip(P, R, F1), start=1):\n",
    "    print(f\"Row {i}: Precision = {p:.3f}, Recall = {r:.3f}, F1 = {f:.3f}\")\n",
    "\n",
    "# Print averages across all rows\n",
    "print(\"\\n=== Average BERTScores ===\")\n",
    "print(f\"Average Precision: {P.mean():.4f}\")\n",
    "print(f\"Average Recall:    {R.mean():.4f}\")\n",
    "print(f\"Average F1:        {F1.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbc5d610-44d4-4868-af6c-ed6818409a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Software\\Anaconda\\envs\\LangChain\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Row-level BERTScores ===\n",
      "Row 1: Precision = 0.839, Recall = 0.887, F1 = 0.862\n",
      "Row 2: Precision = 0.798, Recall = 0.625, F1 = 0.701\n",
      "Row 3: Precision = 0.761, Recall = 0.796, F1 = 0.778\n",
      "Row 4: Precision = 0.846, Recall = 0.948, F1 = 0.894\n",
      "Row 5: Precision = 0.854, Recall = 0.825, F1 = 0.839\n",
      "Row 6: Precision = 0.719, Recall = 0.585, F1 = 0.645\n",
      "Row 7: Precision = 0.674, Recall = 0.741, F1 = 0.706\n",
      "Row 8: Precision = 0.780, Recall = 0.726, F1 = 0.752\n",
      "Row 9: Precision = 0.427, Recall = 0.427, F1 = 0.427\n",
      "Row 10: Precision = 0.612, Recall = 0.653, F1 = 0.632\n",
      "Row 11: Precision = 0.665, Recall = 0.638, F1 = 0.651\n",
      "Row 12: Precision = 0.513, Recall = 0.704, F1 = 0.594\n",
      "Row 13: Precision = 0.467, Recall = 0.405, F1 = 0.433\n",
      "Row 14: Precision = 0.900, Recall = 0.924, F1 = 0.912\n",
      "Row 15: Precision = 0.842, Recall = 0.881, F1 = 0.861\n",
      "Row 16: Precision = 0.968, Recall = 0.964, F1 = 0.966\n",
      "Row 17: Precision = 0.424, Recall = 0.229, F1 = 0.298\n",
      "Row 18: Precision = 0.764, Recall = 0.675, F1 = 0.717\n",
      "Row 19: Precision = 1.000, Recall = 1.000, F1 = 1.000\n",
      "Row 20: Precision = 1.000, Recall = 1.000, F1 = 1.000\n",
      "Row 21: Precision = 0.587, Recall = 0.669, F1 = 0.625\n",
      "Row 22: Precision = 0.817, Recall = 0.760, F1 = 0.788\n",
      "Row 23: Precision = 0.872, Recall = 0.928, F1 = 0.899\n",
      "Row 24: Precision = 0.673, Recall = 0.750, F1 = 0.709\n",
      "Row 25: Precision = 0.793, Recall = 0.844, F1 = 0.817\n",
      "Row 26: Precision = 0.596, Recall = 0.687, F1 = 0.638\n",
      "Row 27: Precision = 0.720, Recall = 0.802, F1 = 0.759\n",
      "Row 28: Precision = 0.840, Recall = 0.921, F1 = 0.879\n",
      "Row 29: Precision = 0.783, Recall = 0.803, F1 = 0.793\n",
      "Row 30: Precision = 0.892, Recall = 0.976, F1 = 0.932\n",
      "Row 31: Precision = 0.774, Recall = 0.836, F1 = 0.804\n",
      "Row 32: Precision = 0.838, Recall = 0.890, F1 = 0.863\n",
      "Row 33: Precision = 0.858, Recall = 0.978, F1 = 0.914\n",
      "Row 34: Precision = 0.475, Recall = 0.923, F1 = 0.627\n",
      "Row 35: Precision = 1.000, Recall = 1.000, F1 = 1.000\n",
      "Row 36: Precision = 0.676, Recall = 0.685, F1 = 0.681\n",
      "Row 37: Precision = 0.688, Recall = 0.834, F1 = 0.754\n",
      "Row 38: Precision = 0.435, Recall = 0.318, F1 = 0.367\n",
      "Row 39: Precision = 0.603, Recall = 0.630, F1 = 0.616\n",
      "Row 40: Precision = 0.931, Recall = 0.947, F1 = 0.939\n",
      "Row 41: Precision = 0.467, Recall = 0.379, F1 = 0.418\n",
      "Row 42: Precision = 0.895, Recall = 0.920, F1 = 0.907\n",
      "Row 43: Precision = 0.909, Recall = 0.925, F1 = 0.917\n",
      "Row 44: Precision = 0.621, Recall = 0.854, F1 = 0.719\n",
      "Row 45: Precision = 0.839, Recall = 0.787, F1 = 0.812\n",
      "Row 46: Precision = 0.620, Recall = 0.753, F1 = 0.680\n",
      "Row 47: Precision = 0.713, Recall = 0.700, F1 = 0.707\n",
      "Row 48: Precision = 0.752, Recall = 0.779, F1 = 0.766\n",
      "Row 49: Precision = 0.550, Recall = 0.639, F1 = 0.591\n",
      "Row 50: Precision = 1.000, Recall = 1.000, F1 = 1.000\n",
      "\n",
      "=== Average BERTScores ===\n",
      "Average Precision: 0.7414\n",
      "Average Recall:    0.7710\n",
      "Average F1:        0.7518\n"
     ]
    }
   ],
   "source": [
    "# Compute BERTScore across rows\n",
    "P, R, F1 = score(preds_2, refs, lang=\"en-sci\", idf=True, rescale_with_baseline=False)\n",
    "\n",
    "# Print per-row precision, recall, and F1\n",
    "print(\"=== Row-level BERTScores ===\")\n",
    "for i, (p, r, f) in enumerate(zip(P, R, F1), start=1):\n",
    "    print(f\"Row {i}: Precision = {p:.3f}, Recall = {r:.3f}, F1 = {f:.3f}\")\n",
    "\n",
    "# Print averages across all rows\n",
    "print(\"\\n=== Average BERTScores ===\")\n",
    "print(f\"Average Precision: {P.mean():.4f}\")\n",
    "print(f\"Average Recall:    {R.mean():.4f}\")\n",
    "print(f\"Average F1:        {F1.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bb397a-a145-4be2-8d46-fd576c87d2cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
